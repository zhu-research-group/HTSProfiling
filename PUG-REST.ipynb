{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Throughput Screening Assay Profiling for Large Chemical Databases\n",
    "\n",
    "This Jupyter Notebook outlines the steps needs to use PubChem's PUG-REST web service to obtain the High-throughput Screening (HTS) results for a set of compounds.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "### Inputs\n",
    "\n",
    "All user-input required parameters are defined in the first cell. First, `data_file` is the name of the file containing the CIDs of compounds you would like to bioprofile. This should be a single-column txt file containing the PubChem CID's of the compounds you wish to obtain HTS data for.  If you have compounds as another identifier (e.g., SMILES) PubChem offers a helpful batch-conversion tool located [here](https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi).  Second, the parameter `min_actives` specifies the number of minimum active Bioactivity Outcome responses a particular PubChem Bioassay should have to be included in the modeling matrix.\n",
    "\n",
    "### Running the notebook\n",
    "\n",
    "To run the notebook, in the tool bar above, select the \"Cell\" menu tab and select \"Run All\". \n",
    "\n",
    "\n",
    "### Outputs\n",
    "\n",
    "With default parameters, two output files will be created in the directory of this Jupyer Notebook.  First, `bioprofile_long.csv` contains the bioprofile in \"long\" format (e.g., each row a unique, CID/AID/Bioactivity Outcome) allong with Bioassay metadata (e.g., Bioassay names, descriptions, targets, etc).  The second file, `bioprofile_matrix.csv` is a file suitable for modeing.  E.g., wide/ matrix format with duplicated Bioactivity Outcomes are merged, and Bioactivity Outcomes are integer encoded (Active/Probe outcomes are converted to 1, Inactive to -1 and Missing/Inconclusive/Unspecified data as 0).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data file as needed\n",
    "# should be a single column list\n",
    "# consisting of cids.\n",
    "\n",
    "data_file = 'data/cids.txt'\n",
    "min_actives = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "def bioassay_post(identifier_list, identifier='cid', output='csv'):\n",
    "    \"\"\" uses PubChem's PUG-Rest service to obtain assay summaries for a target set of chemicals \n",
    "    via a POST request.\n",
    "    \n",
    "    identifer_list: a list of chemical identifiers, the type of identifier should match with that outlined\n",
    "    in the 'identifer' arguement with the default being PubChem Compound Identifier (CID).\n",
    "    \n",
    "    identifier: the chemical identifier (e.g., cid, smiles, etc.) of the chemicals in 'identifier_list'. Can be any chemical identifier \n",
    "    as outlined in the PubChem PUG-Rest documentation.  Default=cid\n",
    "    \n",
    "    output: the output format (e.g., csv, json, etc.) of the \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # convert list of identifers to str\n",
    "    identifier_list = list(map(str, identifier_list))\n",
    "\n",
    "    # make the base URL for the PubChem POST Request\n",
    "    url = 'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/{}/assaysummary/{}'.format(identifier, output)\n",
    "\n",
    "    # encoded_list = [requests.utils.quote(s) for s in identifier_list]\n",
    "\n",
    "    # encoded_list = requests.utils.quote(','.join(identifier_list))\n",
    "    headers = {'Content-Type': 'multipart/form-data'}\n",
    "    data = {identifier: ','.join(identifier_list)}\n",
    "\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    return response\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"\"\" support function for bioprofile, used to create n equaled-sized\n",
    "    sets from an iterable.\n",
    "    \"\"\"\n",
    "    \n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "def bioprofile(identifier_list, identifier='cid', outfile='bioprofile.csv', chunk=False):\n",
    "\n",
    "    num_compounds = len(identifier_list)\n",
    "    \n",
    "    # check to see whether\n",
    "    # the list should be queried\n",
    "    # in chunks of data or \n",
    "    # processed as a whole\n",
    "    if not chunk:\n",
    "        chunk_size = num_compounds\n",
    "    else:\n",
    "        chunk_size = chunk\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    f = open(outfile, 'w')\n",
    "    header_written = False\n",
    "\n",
    "    for gp in grouper(identifier_list, chunk_size):\n",
    "        batch = [cid for cid in gp if cid]\n",
    "        response = bioassay_post(batch, identifier=identifier, output='csv')\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            text = response.text\n",
    "            if not header_written:\n",
    "                f.write(text)\n",
    "                header_written = True\n",
    "            else:\n",
    "                header = text.split('\\n')[0]\n",
    "                text = text.replace(header, '')\n",
    "                f.write(text)\n",
    "            counter = counter + len(batch)\n",
    "            print(\"Retrieved data for {} out of {} compounds.\".format(counter, num_compounds))\n",
    "        else:\n",
    "            f.close()\n",
    "            os.remove('data/assay_data.csv')\n",
    "            print(\"Error: {}\".format(response.status_code))\n",
    "            return\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "def make_matrix(data_file, min_actives=0, merge_dups_by='max', outfile='bioprofile_matrix.csv'):\n",
    "    \"\"\" will turn assay data file into wide (i.e., a matrix) format but performs all filtering in\n",
    "        long format to save RAM\"\"\"\n",
    "\n",
    "    df = pd.read_csv(data_file, usecols=['AID', 'CID', 'Bioactivity Outcome'])\n",
    "    df['Bioactivity Outcome'] = df['Bioactivity Outcome'] \\\n",
    "                                    .replace('Inactive', -1) \\\n",
    "                                    .replace('Active', 1) \\\n",
    "                                    .replace('Probe', 1) \\\n",
    "                                    .replace('Inconclusive', 0) \\\n",
    "                                    .replace('Unspecified', 0) \\\n",
    "                                    .fillna(0)\n",
    "\n",
    "    df['Activity Transformed'] = df.groupby(['CID', 'AID'])['Bioactivity Outcome'].transform(merge_dups_by)\n",
    "    \n",
    "    # for the num actives count, a CID is considered active\n",
    "    # for a given AID if it has an active response for any of its\n",
    "    # bioactivity outcomes for that AID.\n",
    "    df['Bioactivity Outcome Max'] = df.groupby(['CID', 'AID'])['Bioactivity Outcome'].transform('max')\n",
    "    \n",
    "    # take only one response for a \n",
    "    # CID/AID pair, ie., the transformed\n",
    "    # bioactivity value  \n",
    "    df = df.drop_duplicates(['CID', 'AID', 'Activity Transformed'])\n",
    "    # CID/AID/Bioactivity Outcome should be unique\n",
    "    # just like CID/AID/Bioactivity Outcome Maz\n",
    "    df_tmp = df.groupby('AID')['Bioactivity Outcome Max'].apply(lambda x: (x == 1).sum()).reset_index(name='Num_Active')\n",
    "    df = df.merge(df_tmp)\n",
    "    df = df[df.Num_Active >= min_actives]\n",
    "    \n",
    "\n",
    "\n",
    "    # turn into wide format\n",
    "    matrix = df.pivot(index='CID', columns='AID', values='Activity Transformed').fillna(0)\n",
    "    \n",
    "    matrix.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv file and read\n",
    "# store identifiers as a list\n",
    "target_compounds = []\n",
    "\n",
    "csv_file = open(data_file, \"r\")\n",
    "\n",
    "for line in csv_file:\n",
    "    cmp = line.strip()\n",
    "    target_compounds.append(cmp)\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collects data in 'long' format\n",
    "# and writes to a csv file specified\n",
    "# in the outfile parameter\n",
    "bioprofile(target_compounds, chunk=100, outfile='bioprofile_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a matrix that is\n",
    "# more suitable for modeling\n",
    "make_matrix('bioprofile_long.csv', min_actives=min_actives, outfile='bioprofile_matrix.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
